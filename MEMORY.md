# Ã‰TAT DES LIEUX COMPLET - Circuit Synthesis GNN
**Date: 2026-01-07**
**Projet: SynthÃ¨se de circuits Ã©lectriques par IA Ã  partir de courbes d'impÃ©dance Z(f)**

---

## ğŸ¯ OBJECTIF DU PROJET

PrÃ©dire la topologie d'un circuit Ã©lectrique (composants R, L, C et leurs connexions) Ã  partir de courbes d'impÃ©dance complexe Z(f) mesurÃ©es sur 100 frÃ©quences.

**Approche**: 100% donnÃ©es synthÃ©tiques
1. GÃ©nÃ©rer des circuits alÃ©atoires avec topologie et valeurs alÃ©atoires
2. Calculer leur impÃ©dance Z(f) avec solveur MNA (Modified Nodal Analysis)
3. EntraÃ®ner modÃ¨le supervisÃ©: Input = Z(f), Output = Circuit vectoriel

---

## ğŸ“Š HISTORIQUE CHRONOLOGIQUE

### Phase 1: Approche Initiale (DÃ©cembre 2025)
**Architecture**: GraphSolver + RobustSolver
- ModÃ¨le prÃ©dit matrices d'adjacence (edge_types, edge_values)
- Solver MNA reconstruit Z(f) pendant l'entraÃ®nement
- **ProblÃ¨me**: CoincÃ© Ã  238% d'erreur (mode collapse)

**Dataset initial**: `gnn_750k.pt`
- 750k circuits gÃ©nÃ©rÃ©s
- **ProblÃ¨me identifiÃ©**: Seulement 9.9% RLC, 57% circuits simples
- RÃ©sultat: ModÃ¨le prÃ©dit toujours des courbes plates (comportement rÃ©sistif)

### Phase 2: Pivot vers SupervisÃ© (DÃ©cembre 2025)
**DÃ©cision**: Abandonner solver pendant training, passer en supervisÃ© pur
- CrÃ©Ã© `train_supervised.py`
- Pas de reconstruction Z(f), juste loss sur composants
- **RÃ©sultat**: Meilleurs performances (type_acc ~48% sur ancien dataset)

### Phase 3: ProblÃ¨me de Dataset (Janvier 2026)
**Constat**: Les prÃ©dictions sont plates car dataset inadÃ©quat

**Analyse dataset `gnn_750k.pt`**:
```
Distribution:
  - RLC (R+L+C): 74,366 (9.9%)
  - R seul: 141,333 (18.8%)
  - L seul: 142,006 (18.9%)
  - C seul: 141,793 (18.9%)
  - Circuits simples (â‰¤3 comp): 345,722 (46.1%)
```

**ProblÃ¨me**: Pas assez de circuits RLC complexes pour apprendre les rÃ©sonances

### Phase 4: GÃ©nÃ©ration Dataset RLC (Janvier 2026) âœ… COMPLÃ‰TÃ‰

**Modifications code**:

1. **`core/graph_repr.py`** - Ajout `force_rlc` parameter
   ```python
   def random_circuit(force_rlc: bool = False):
       if force_rlc:
           # Force 6-10 composants, 5-8 nÅ“uds
           # Garantit R+L+C (min 2 de chaque)
           # Permet branches parallÃ¨les (40% chance)
           # Ã‰vite nÅ“uds morts et courts-circuits INâ†”GND
   ```

2. **`data/dataset.py`** - Ajout `rlc_ratio` parameter
   ```python
   def generate_dataset(rlc_ratio: float = 0.7):
       # 70% circuits RLC complexes
       # 30% autres (simples R/L/C ou paires RL/RC/LC)
   ```

3. **Fixes importants**:
   - âŒ NÅ“uds morts (nÅ“uds avec 1 seule connexion) â†’ FixÃ© (2 connexions min)
   - âŒ Courts-circuits INâ†”GND (bypass tout le circuit) â†’ FixÃ© (filtrage)
   - âŒ Courbes plates au lieu de rÃ©sonances â†’ FixÃ© (branches parallÃ¨les)

**Nouveau dataset**: `gnn_750k_rlc.pt` (gÃ©nÃ©rÃ© 2026-01-07)
```
Distribution finale:
  - RLC (all 3 types): 589,511 (78.6%) âœ…
  - RLC complex (â‰¥6 comp): 589,511 (78.6%) âœ…
  - Simple (â‰¤3 comp): 74,077 (9.9%)

Validation:
  âœ… Dimensions: edge_types (750000, 8, 8), edge_values (750000, 8, 8)
  âœ… Pas de NaN/Inf
  âœ… Nodes range: 2-8
  âœ… Impedance mag: -5.64 to 11.60 (log scale)
  âœ… Impedance phase: -1.57 to 1.57 radians
```

---

## ğŸ—ï¸ ARCHITECTURE ACTUELLE

### Dataset
- **Fichier**: `outputs/data/gnn_750k_rlc.pt`
- **Taille**: 1.2 GB
- **Ã‰chantillons**: 750,000 circuits
- **Split**: 600k train / 75k val / 75k test

### ReprÃ©sentation Circuit
**Format**: Matrices d'adjacence 8Ã—8 (MAX_NODES=8)
- `edge_types[i,j]`: Type de composant entre nÅ“uds iâ†”j
  - 0 = NONE (pas de connexion)
  - 1 = COMP_R (rÃ©sistance)
  - 2 = COMP_L (inductance)
  - 3 = COMP_C (capacitance)
- `edge_values[i,j]`: Valeur du composant (linÃ©aire, pas log)
- `num_nodes`: Nombre de nÅ“uds du circuit (2-8)

**Conventions**:
- NÅ“ud 0 = GND (ground, toujours prÃ©sent)
- NÅ“ud 1 = IN (input, toujours prÃ©sent)
- NÅ“uds 2-7 = NÅ“uds internes

### ReprÃ©sentation ImpÃ©dance Z(f)
**Format**: Tenseur (batch, 2, 100)
- Channel 0: logâ‚â‚€(|Z|) - magnitude en log
- Channel 1: arg(Z) - phase en radians
- 100 frÃ©quences logarithmiques: 10 Hz â†’ 1 MHz

### ModÃ¨le Neural: CircuitPredictor
**Input**: ImpÃ©dance Z(f) â†’ (batch, 2, 100)

**Encoder**:
```
MLP: 200 â†’ 1024 â†’ 1024 â†’ 512
BatchNorm + ReLU + Dropout(0.3)
```

**Decoder**: Dual-head architecture
1. **Type Head**: PrÃ©dit edge_types (classification)
   - Output: (batch, 8, 8, 4) = 4 classes par edge
   - Loss: CrossEntropyLoss

2. **Value Head**: PrÃ©dit edge_values (rÃ©gression)
   - Output: (batch, 8, 8) = valeur continue
   - Loss: MSE sur logâ‚â‚€(valeur)

**ParamÃ¨tres**: 7,373,777

---

## ğŸ”§ APPROCHES TESTÃ‰ES

### Approche 1: RobustSolver (Ã‰CHEC)
**Concept**: PrÃ©dire circuit â†’ Solver MNA â†’ Loss sur Z(f)

**Fichiers**:
- `solver/robust_solver.py`
- `scripts/train_robust_solver.py`

**ProblÃ¨mes**:
1. **InstabilitÃ© numÃ©rique**: Admittances 10â»Â¹â¶ Ã  10Â¹Â² (28 ordres de grandeur)
2. **torch.linalg.solve() instable** sur GPU
3. **Mode collapse**: CoincÃ© Ã  238% d'erreur
4. **Pas de gradient**: Circuit â†’ Z(f) non-diffÃ©rentiable proprement

**RÃ©sultat**: âŒ AbandonnÃ©

### Approche 2: GraphSolver (Ã‰CHEC)
**Concept**: Comme RobustSolver mais implÃ©mentation alternative

**Fichiers**:
- `solver/graph_solver.py`
- `scripts/train_graph_solver.py`

**ProblÃ¨mes**:
1. **Bug permute**: `.permute(0,2,1)` sur tenseur 2D â†’ RuntimeError
2. **MÃªmes instabilitÃ©s** que RobustSolver
3. **Pas testÃ© Ã  fond** (pivot vers supervisÃ©)

**Fix appliquÃ©** (2026-01-07):
- Lignes 167-168, 174: RemplacÃ© `.permute()` par `.transpose()`
- Non testÃ© aprÃ¨s fix

**RÃ©sultat**: âŒ Non concluant

### Approche 3: Supervised (EN COURS - MEILLEUR) âœ…
**Concept**: PrÃ©dire directement le circuit, pas de solver

**Fichier**: `scripts/train_supervised.py`

**Architecture**:
- Input: Z(f) â†’ (batch, 2, 100)
- Output: edge_types + edge_values
- Loss: CrossEntropy (types) + MSE (values)

**Hyperparams actuels**:
```python
--epochs 50
--lr 0.0003
--batch-size 128
--type-weight 1.0
--value-weight 1.0
--nodes-weight 0.5
--tau-end 0.3
--tau-anneal-epochs 50
```

**Performances**:

**Sur ancien dataset** (gnn_750k.pt, 9.9% RLC):
- Type accuracy: ~48%
- PrÃ©dictions: Courbes plates (biais dataset)

**Sur nouveau dataset** (gnn_750k_rlc.pt, 78.6% RLC) - EN COURS:
- Epoch 1, Batch 1: type_acc=35.7%
- Epoch 1, Batch 10: type_acc=77.9%
- Epoch 1, Batch 50: type_acc=80.0%
- **Progression rapide** âœ…

**Statut**: ğŸŸ¢ TRAINING EN COURS (lancÃ© 2026-01-07 23:34 UTC)

---

## ğŸ“ STRUCTURE FICHIERS

```
/Users/bilelazz/Documents/PRI/
â”œâ”€â”€ circuit_synthesis_gnn/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ constants.py          # MAX_NODES=8, COMP_R/L/C
â”‚   â”‚   â””â”€â”€ graph_repr.py         # random_circuit(force_rlc=True)
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ dataset.py            # generate_dataset(rlc_ratio=0.7)
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ circuit_predictor.py  # CircuitPredictor (dual-head)
â”‚   â”œâ”€â”€ solver/
â”‚   â”‚   â”œâ”€â”€ robust_solver.py      # âŒ Instable
â”‚   â”‚   â””â”€â”€ graph_solver.py       # âŒ Bug permute (fixÃ© mais non testÃ©)
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ loss.py               # Loss supervisÃ© + NaN protection
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ train_supervised.py   # âœ… EN COURS
â”‚   â”‚   â”œâ”€â”€ train_graph_solver.py
â”‚   â”‚   â”œâ”€â”€ train_robust_solver.py
â”‚   â”‚   â”œâ”€â”€ validate_dataset.py
â”‚   â”‚   â””â”€â”€ generate_clean_dataset.py
â”‚   â””â”€â”€ outputs/
â”‚       â”œâ”€â”€ data/
â”‚       â”‚   â””â”€â”€ gnn_750k_rlc.pt   # âœ… Dataset actuel
â”‚       â””â”€â”€ gnn_supervised_rlc_v1/ # Checkpoints en cours
â”œâ”€â”€ generate_complex_dataset.sh   # GÃ©nÃ©ration dataset RLC
â”œâ”€â”€ launch_supervised.sh          # âœ… Lance training supervisÃ©
â””â”€â”€ launch_graph_solver.sh        # Lance training GraphSolver
```

**Serveur OVH**: ubuntu@57.128.57.31
- GPU: Quadro RTX 5000
- Dataset: `~/circuit_synthesis_gnn/outputs/data/gnn_750k_rlc.pt`
- Logs: `~/circuit_synthesis_gnn/training_supervised.log`

---

## ğŸ§ª TESTS EFFECTUÃ‰S

### Tests sur ancien dataset (gnn_750k.pt)
**Scripts crÃ©Ã©s**:
- `/tmp/test_rlc_generation.py` - VÃ©rification gÃ©nÃ©ration RLC
- `/tmp/show_complex_circuit.py` - Affichage circuits complexes
- `/tmp/draw_circuit_ascii.py` - Visualisation ASCII circuits

**Observations**:
- Circuits simples prÃ©dominants (46%)
- Peu de circuits RLC (9.9%)
- Courbes Z(f) plates (pas de rÃ©sonance)

### Tests sur nouveau dataset (gnn_750k_rlc.pt) âœ…
**Validation**:
```bash
python scripts/validate_dataset.py outputs/data/gnn_750k_rlc.pt
# âœ… PASSED - Shapes correctes, pas de NaN
```

**Analyse distribution**:
```python
# 78.6% RLC complexes (â‰¥6 composants)
# 100% des RLC ont branches parallÃ¨les possibles
# RÃ©duction circuits simples: 46.1% â†’ 9.9%
```

---

## ğŸ” PROBLÃˆMES RÃ‰SOLUS

### 1. Dimension Mismatch Dataset/Code âŒâ†’âœ…
**ProblÃ¨me**: Dataset (8Ã—8) vs Code (MAX_NODES=4)
**Solution**: RestaurÃ© MAX_NODES=8 dans `constants.py:38`

### 2. Data Augmentation Polluting Val/Test âŒâ†’âœ…
**ProblÃ¨me**: Augmentation avant split â†’ metrics biaisÃ©s
**Solution**: `augment=False` dans gÃ©nÃ©ration dataset

### 3. GraphSolver Permute Bug âŒâ†’âœ…
**ProblÃ¨me**: `.permute(0,2,1)` sur tenseur 2D
**Solution**: RemplacÃ© par `.transpose(0,1)` (lignes 167-168, 174)

### 4. RobustSolver Numerical Instability âŒâ†’â“
**ProblÃ¨me**: InstabilitÃ© torch.linalg.solve, mode collapse
**Solution**: Pivot vers supervisÃ© (pas de solver)

### 5. Dataset Imbalance âŒâ†’âœ…
**ProblÃ¨me**: 9.9% RLC, 46% simples
**Solution**: Nouveau dataset 78.6% RLC complexes

### 6. Flat Predictions âŒâ†’ğŸŸ¡
**ProblÃ¨me**: ModÃ¨le prÃ©dit courbes plates
**Solution**: Dataset RLC â†’ Testing en cours

### 7. Dead Nodes âŒâ†’âœ…
**ProblÃ¨me**: NÅ“uds avec 1 seule connexion (N7 dans le vide)
**Solution**: Force 2 connexions min lors crÃ©ation nouveaux nÅ“uds

### 8. INâ†”GND Short Circuits âŒâ†’âœ…
**ProblÃ¨me**: Connexions directes INâ†’GND (bypass circuit)
**Solution**: Filtrage lors sÃ©lection nodes (`graph_repr.py`)

---

## ğŸ“ˆ MÃ‰TRIQUES Ã€ SURVEILLER

### Training (Supervised)
- **type_acc**: Accuracy prÃ©diction type composant (NONE/R/L/C)
- **value_mae**: Mean Absolute Error sur logâ‚â‚€(valeurs)
- **nodes_acc**: Accuracy prÃ©diction nombre de nÅ“uds
- **total_loss**: Loss combinÃ©e

### Validation
- **val_type_acc**: Type accuracy sur validation set
- **val_value_mae**: Value MAE sur validation set
- VÃ©rifier: val_acc < train_acc (pas d'overfitting)

### Post-Training
- **Reconstruction Z(f)**: Comparer Z_pred vs Z_true
  - Magnitude error (%)
  - Phase error (Â°)
- **Circuit validity**: % circuits valides (connexes, pas de dead nodes)
- **Component distribution**: % R/L/C correct

---

## ğŸ¯ PROCHAINES Ã‰TAPES

### Court terme (En cours)
1. âœ… Training supervisÃ© avec dataset RLC (EN COURS)
2. â³ Attendre fin epoch 1 (~8min)
3. â³ VÃ©rifier mÃ©triques validation
4. â³ Analyser courbes prÃ©dites (flat vs rÃ©sonance)

### Si results OK (type_acc > 85%, courbes rÃ©alistes)
1. Laisser training complet (50 epochs)
2. Ã‰valuer test set
3. Visualiser prÃ©dictions qualitatives
4. Mesurer reconstruction error Z(f)

### Si results moyens (type_acc ~70%, courbes encore plates)
1. Augmenter epochs â†’ 100
2. Tuning hyperparams (lr, batch_size, weights)
3. Data augmentation (bruit sur Z(f) pendant training)
4. Architecture improvements (+ de couches, attention)

### Si results mauvais (type_acc < 60%)
1. Debugging: VÃ©rifier inputs/outputs
2. Analyser erreurs: quels types de circuits Ã©chouent?
3. Simplifier dataset (moins de nÅ“uds, moins de composants)
4. ConsidÃ©rer approche alternative (Graph Neural Network)

---

## ğŸ”¬ HYPOTHÃˆSES Ã€ TESTER

### Dataset
- [ ] 78.6% RLC est-il suffisant? (vs 90%?)
- [ ] Circuits trop complexes? (6-10 comp, 5-8 nodes)
- [ ] Besoin de plus de samples? (750k vs 1M+)
- [ ] Distribution valeurs R/L/C appropriÃ©e?

### Architecture
- [ ] Dual-head est optimal? (vs single output)
- [ ] MLP suffit? (vs CNN, Transformer, GNN)
- [ ] 100 frÃ©quences suffisant? (vs 200)
- [ ] ReprÃ©sentation log|Z| optimale? (vs rÃ©el/imag)

### Training
- [ ] Weights types/values/nodes optimaux?
- [ ] Batch size 128 OK? (vs 64 ou 256)
- [ ] Learning rate 3e-4 appropriÃ©?
- [ ] Besoin scheduler? (StepLR, CosineAnnealing)

---

## ğŸ“Š RÃ‰SULTATS ATTENDUS

### Baseline (ancien dataset, 9.9% RLC)
- Type accuracy: ~48%
- PrÃ©dictions: Courbes plates
- **Conclusion**: Dataset insuffisant

### Target (nouveau dataset, 78.6% RLC)
- Type accuracy: >85% (espÃ©rÃ©)
- Value MAE: <0.5 log units (espÃ©rÃ©)
- Courbes: RÃ©sonances visibles (espÃ©rÃ©)
- **Validation**: En cours...

### Success Criteria
- âœ… Type accuracy >80% sur test set
- âœ… Courbes Z(f) reconstruct error <20%
- âœ… Circuits valides (connexes, pas de dead nodes)
- âœ… Distribution R/L/C proche rÃ©alitÃ©

---

## ğŸ’¾ COMMANDES UTILES

### Monitoring
```bash
# SSH server
ssh ubuntu@57.128.57.31

# Check training log
tail -f ~/circuit_synthesis_gnn/training_supervised.log

# Check GPU usage
nvidia-smi

# Check process
ps aux | grep python
```

### Dataset
```bash
# Validate dataset
cd ~/circuit_synthesis_gnn
python scripts/validate_dataset.py outputs/data/gnn_750k_rlc.pt

# Analyze distribution
python << EOF
import torch
data = torch.load('outputs/data/gnn_750k_rlc.pt')
print(data['edge_types'].shape)
print(data['impedances'].shape)
EOF
```

### Training
```bash
# Launch supervised
./launch_supervised.sh

# Launch GraphSolver (if needed)
./launch_graph_solver.sh

# Stop training
ssh ubuntu@57.128.57.31 "pkill -9 python"
```

---

## ğŸš¨ POINTS D'ATTENTION

### Critiques
1. **MAX_NODES=8**: Si on augmente, TOUT le dataset doit Ãªtre rÃ©gÃ©nÃ©rÃ©
2. **Dataset immuable**: Toute modif `graph_repr.py` â†’ rÃ©gÃ©nÃ©ration complÃ¨te
3. **GPU memory**: Batch size limitÃ© par VRAM (16GB Quadro RTX 5000)
4. **Overfitting risk**: 7.3M params sur 600k samples â†’ surveiller val loss

### Best Practices
- âœ… Toujours valider dataset aprÃ¨s gÃ©nÃ©ration
- âœ… Sauvegarder checkpoints tous les 5 epochs
- âœ… Logger mÃ©triques train + val
- âœ… Tester sur subset avant training complet
- âœ… Backup ancien dataset avant rÃ©gÃ©nÃ©ration

---

## ğŸ“ NOTES DÃ‰VELOPPEUR

### DÃ©cisions Architecturales
1. **Pourquoi supervisÃ©?**
   - Solver trop instable (mode collapse)
   - Pas de gradient propre circuitâ†’Z(f)
   - SupervisÃ© converge mieux

2. **Pourquoi matrices 8Ã—8?**
   - MAX_NODES=8 permet circuits complexes
   - Padding Ã  0 pour circuits plus petits
   - Trade-off mÃ©moire vs complexitÃ©

3. **Pourquoi 78.6% RLC?**
   - Target 70%, obtenu 78.6%
   - VariabilitÃ© random seed
   - Assez pour apprendre rÃ©sonances

### Bugs Historiques
1. **np.random.choice([(a,b), (c,d)])** â†’ ValueError
   - Fix: `pairs[np.random.randint(0, len(pairs))]`

2. **randint(3, max_comp)** quand max_comp=2 â†’ ValueError
   - Fix: `effective_max = max(3, max_comp)`

3. **Dead nodes** (N7 dans le vide)
   - Fix: Force 2 connexions min lors crÃ©ation

4. **INâ†”GND short** (bypass circuit)
   - Fix: Filter GND quand node_a=IN

---

## ğŸ“ LEÃ‡ONS APPRISES

### Dataset Quality > Model Complexity
- Ancien dataset (9.9% RLC) â†’ Ã‰chec mÃªme avec bon modÃ¨le
- Nouveau dataset (78.6% RLC) â†’ RÃ©sultats prometteurs immÃ©diatement

### Supervised > Differentiable Solver
- Solver trop instable (admittances 28 ordres de magnitude)
- Pas de gradient propre pour backprop
- SupervisÃ© converge mieux, plus stable

### Validation Early
- Valider dataset AVANT training (shapes, NaN, distribution)
- Tester gÃ©nÃ©ration sur petits Ã©chantillons d'abord
- Visualiser circuits gÃ©nÃ©rÃ©s (dead nodes, shorts)

### Iteration Speed
- GÃ©nÃ©ration dataset: ~35min (750k circuits)
- Training: ~8min/epoch (4688 batches)
- Feedback rapide crucial pour expÃ©rimentation

---

**STATUT ACTUEL**: ğŸŸ¢ TRAINING SUPERVISÃ‰ EN COURS
**Dataset**: gnn_750k_rlc.pt (78.6% RLC, 750k circuits)
**ModÃ¨le**: CircuitPredictor (7.3M params, dual-head)
**Epoch**: 1/50 en cours
**MÃ©triques initiales**: type_acc montant rapidement (35%â†’80% en 50 batches)

**Prochaine action**: Attendre fin epoch 1, analyser mÃ©triques validation
